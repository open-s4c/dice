/*
 * Copyright (C) Huawei Technologies Co., Ltd. 2023-2025. All rights reserved.
 * SPDX-License-Identifier: MIT
 */
/*******************************************************************************
 * @file tsan.c
 * @brief Implements a TSAN interface that publishes events.
 *
 ******************************************************************************/
#include <assert.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#include <dice/intercept/memaccess.h>
#include <dice/interpose.h>
#include <dice/module.h>

DICE_MODULE_INIT()

#define _tmpl_mute // ----------- simple empty macros to make clangd happy -----
#define _tmpl_map(...)
#define _tmpl_begin(...)
#define _tmpl_end(...)
#define __atomic_fetch_Op __atomic_exchange_n
#define uintBITS_t        int
#define PARAM_SUF         0
#define EV_TYPE(...)      EVENT_MA_READ
#define UPCASE
#define SZ 0
#define FUNC
#define BITS         0
#define _tmpl_unmute // --------------------------------------------------------
_tmpl_map(nix, );
_tmpl_map(UPCASE, _tmpl_upcase);
_tmpl_map(EV_TYPE, EVENT_MA_UPCASE);
_tmpl_map(PARAM_strong, 0);
_tmpl_map(PARAM_weak, 1);

/* empty tsan initialization */
void
__tsan_init()
{
}
void
__tsan_write_range(void)
{
}
void
__tsan_read_range(void)
{
}

/* empty vptr impl */
void
__tsan_vptr_read(void **vptr_p)
{
    (void)vptr_p;
}
void
__tsan_vptr_update(void **vptr_p, void *new_val)
{
    (void)vptr_p;
    (void)new_val;
}

/* with GCC version < 10, this symbols is defined */
void
internal_sigreturn(void)
{
}

void
__tsan_mutex_pre_lock(void *addr, unsigned flags)
{
    (void)addr;
    (void)flags;
}
void
__tsan_mutex_post_lock(void *addr, unsigned flags, int recursion)
{
    (void)addr;
    (void)flags;
    (void)recursion;
}
int
__tsan_mutex_pre_unlock(void *addr, unsigned flags)
{
    (void)addr;
    (void)flags;
    return 0;
}
void
__tsan_mutex_post_unlock(void *addr, unsigned flags)
{
    (void)addr;
    (void)flags;
}
void
__tsan_mutex_create(void *addr, unsigned flags)
{
    (void)addr;
    (void)flags;
}
void
__tsan_mutex_destroy(void *addr, unsigned flags)
{
    (void)addr;
    (void)flags;
}
void
__tsan_acquire(void *addr)
{
    (void)addr;
}
void
__tsan_release(void *addr)
{
    (void)addr;
}
void *
__tsan_memset(void *b, int c, size_t len)
{
    return memset(b, c, len);
}
void *
__tsan_memcpy(void *dst, const void *src, size_t len)
{
    return memcpy(dst, src, len);
}
/* plain reads and writes */
_tmpl_begin(PFX = [[nix; unaligned_]], FUNC = [[read; write]],
            SZ = [[1; 2; 4; 8; 16]]);
void
__tsan_PFXFUNCSZ(void *a)
{
    memaccess_t ma = {
        .pc      = (INTERPOSE_PC),
        .func    = "PFXFUNCSZ",
        .addr    = (uintptr_t)a,
        .size    = SZ,
        .argu128 = 0,
        .failed  = false,
    };

    PS_PUBLISH(INTERCEPT_EVENT, EV_TYPE(FUNC), &ma, 0);
}
_tmpl_end();

/* plain reads and writes 2 values */
_tmpl_begin(FUNC = [[read; write]], SZ = [[1; 2; 4; 8; 16]]);
void
__tsan_FUNCSZ_pc(void *a, void *b)
{
    (void)a;
    (void)b;
    PS_PUBLISH(INTERCEPT_EVENT, EV_TYPE(FUNC), 0, 0);
}
_tmpl_end();

/* atomic loads */
_tmpl_begin(BITS = [[8; 16; 32; 64]]);
uintBITS_t
__tsan_atomicBITS_load(const volatile uintBITS_t *a, int mo)
{
    (void)mo;
    memaccess_t ma = {
        .pc      = (INTERPOSE_PC),
        .func    = "atomicBITS_load",
        .addr    = (uintptr_t)a,
        .size    = (BITS >> 3),
        .argu128 = 0,
        .failed  = false,
    };

    metadata_t md = {0};
    PS_PUBLISH(INTERCEPT_BEFORE, EV_TYPE(AREAD), &ma, &md);
    uintBITS_t r = __atomic_load_n(a, __ATOMIC_SEQ_CST);
    ma.argu128   = (__uint128_t)r;
    PS_PUBLISH(INTERCEPT_AFTER, EV_TYPE(AREAD), &ma, &md);
    return r;
}
_tmpl_end();

/* atomic stores */
_tmpl_begin(BITS = [[8; 16; 32; 64]]);
void
__tsan_atomicBITS_store(volatile uintBITS_t *a, uintBITS_t v, int mo)
{
    (void)mo;
    memaccess_t ma = {
        .pc      = INTERPOSE_PC,
        .func    = "atomicBITS_store",
        .addr    = (uintptr_t)a,
        .size    = (BITS >> 3),
        .argu128 = (__uint128_t)v,
        .failed  = false,
    };

    metadata_t md = {0};
    PS_PUBLISH(INTERCEPT_BEFORE, EV_TYPE(AWRITE), &ma, &md);
    __atomic_store_n(a, v, __ATOMIC_SEQ_CST);
    PS_PUBLISH(INTERCEPT_AFTER, EV_TYPE(AWRITE), &ma, &md);
}
_tmpl_end();


/* xchg */
_tmpl_begin(BITS = [[8; 16; 32; 64]]);
uintBITS_t
__tsan_atomicBITS_exchange(volatile uintBITS_t *a, uintBITS_t v, int mo)
{
    (void)mo;
    memaccess_t ma = {
        .pc      = INTERPOSE_PC,
        .func    = "atomicBITS_exchange",
        .addr    = (uintptr_t)a,
        .size    = (BITS >> 3),
        .argu128 = (__uint128_t)v,
        .failed  = false,
    };

    metadata_t md = {0};
    PS_PUBLISH(INTERCEPT_BEFORE, EV_TYPE(XCHG), &ma, &md);
    uintBITS_t r = __atomic_exchange_n(a, v, __ATOMIC_SEQ_CST);
    ma.argu128   = (__uint128_t)r;
    PS_PUBLISH(INTERCEPT_AFTER, EV_TYPE(XCHG), &ma, &md);
    return r;
}
_tmpl_end();

/* fetch_RMW */
_tmpl_begin(Op = [[add; sub; and; or ; xor; nand]], BITS = [[8; 16; 32; 64]]);
uintBITS_t
__tsan_atomicBITS_fetch_Op(volatile uintBITS_t *a, uintBITS_t v, int mo)
{
    (void)mo;
    memaccess_t ma = {
        .pc      = INTERPOSE_PC,
        .func    = "atomicBITS_fetch_Op",
        .addr    = (uintptr_t)a,
        .size    = (BITS >> 3),
        .argu128 = (__uint128_t)v,
        .failed  = false,
    };

    metadata_t md = {0};
    PS_PUBLISH(INTERCEPT_BEFORE, EV_TYPE(RMW), &ma, &md);
    uintBITS_t r = __atomic_fetch_Op(a, v, __ATOMIC_SEQ_CST);
    ma.argu128   = (__uint128_t)r;
    PS_PUBLISH(INTERCEPT_AFTER, EV_TYPE(RMW), &ma, &md);
    return r;
}
_tmpl_end();


/* compare_exchange_{strong,weak} */
_tmpl_begin(SUF = [[strong; weak]], BITS = [[8; 16; 32; 64]]);
int
__tsan_atomicBITS_compare_exchange_SUF(volatile uintBITS_t *a, uintBITS_t *c,
                                       uintBITS_t v, int mo)
{
    (void)mo;
    memaccess_t ma = {
        .pc      = INTERPOSE_PC,
        .func    = "atomicBITS_compare_exchange_SUF",
        .addr    = (uintptr_t)a,
        .size    = (BITS >> 3),
        .argu128 = (__uint128_t)v,
        .failed  = false,
    };

    metadata_t md = {0};
    PS_PUBLISH(INTERCEPT_BEFORE, EV_TYPE(CMPXCHG), &ma, &md);
    int r = __atomic_compare_exchange_n(a, c, v, PARAM_SUF, __ATOMIC_SEQ_CST,
                                        __ATOMIC_SEQ_CST);
    assert(r == 0 || r == 1);
    ma.failed = r == 0;
    PS_PUBLISH(INTERCEPT_AFTER, EV_TYPE(CMPXCHG), &ma, &md);
    return r;
}
_tmpl_end();

/* compare_exchange_val */
_tmpl_begin(BITS = [[8; 16; 32; 64]]);
uintBITS_t
__tsan_atomicBITS_compare_exchange_val(volatile uintBITS_t *a, uintBITS_t c,
                                       uintBITS_t v, int mo)
{
    (void)mo;
    memaccess_t ma = {
        .pc      = INTERPOSE_PC,
        .func    = "atomicBITS_compare_exchange_val",
        .addr    = (uintptr_t)a,
        .size    = (BITS >> 3),
        .argu128 = (__uint128_t)v,
        .failed  = false,
    };

    metadata_t md = {0};
    PS_PUBLISH(INTERCEPT_BEFORE, EV_TYPE(CMPXCHG), &ma, &md);
    int r = __atomic_compare_exchange_n(a, &c, v, 0, __ATOMIC_SEQ_CST,
                                        __ATOMIC_SEQ_CST);
    assert(r == 0 || r == 1);
    ma.failed = r == 0;
    PS_PUBLISH(INTERCEPT_AFTER, EV_TYPE(CMPXCHG), &ma, &md);
    return c;
}
_tmpl_end();

/* atomic fences */
void
__tsan_atomic_thread_fence(int mo)
{
    (void)mo;

    metadata_t md = {0};
    PS_PUBLISH(INTERCEPT_BEFORE, EVENT_MA_FENCE, 0, &md);
    __atomic_thread_fence(__ATOMIC_SEQ_CST);
    PS_PUBLISH(INTERCEPT_AFTER, EVENT_MA_FENCE, 0, &md);
}

void
__tsan_atomic_signal_fence(int mo)
{
    (void)mo;

    metadata_t md = {0};
    PS_PUBLISH(INTERCEPT_BEFORE, EVENT_MA_FENCE, 0, &md);
    __atomic_signal_fence(__ATOMIC_SEQ_CST);
    PS_PUBLISH(INTERCEPT_AFTER, EVENT_MA_FENCE, 0, &md);
}
